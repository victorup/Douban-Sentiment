{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\python3.6\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "D:\\Anaconda\\envs\\python3.6\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba # 结巴分词\n",
    "# gensim用来加载预训练word vector\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用gensim加载预训练中文分词embedding\n",
    "corpus_path = r'D:\\victor\\Graduate\\study\\code\\NLP\\sgns.zhihu.bigram/'\n",
    "cn_model = KeyedVectors.load_word2vec_format(corpus_path + 'sgns.zhihu.bigram', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7849\n",
      "7344\n"
     ]
    }
   ],
   "source": [
    "# 获得样本的索引，样本存放于两个文件夹中，\n",
    "# 分别为 正面评价'pos'文件夹 和 负面评价'neg'文件夹\n",
    "# neg文件夹中有7849个txt文件，每个文件中是一例评价\n",
    "# pos文件夹中有7344个txt文件，每个文件中是一例评价\n",
    "import os\n",
    "path = (r'D:\\victor\\Graduate\\study\\code\\web_data_mining\\film_review\\data')\n",
    "\n",
    "pos_txts = os.listdir(os.path.join(path, 'pos'))\n",
    "neg_txts = os.listdir(path + '/neg')\n",
    "print(len(neg_txts))\n",
    "print(len(pos_txts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总共: 15193\n"
     ]
    }
   ],
   "source": [
    "print( '样本总共: '+ str(len(pos_txts) + len(neg_txts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有的评价内容放置到一个list里\n",
    "\n",
    "train_texts_orig = [] # 存储所有评价，每例评价为一条string\n",
    "\n",
    "# 添加完所有样本之后，train_texts_orig为一个含有15193条文本的list\n",
    "# 其中前7849条文本为正面评价，后7344条为负面评价\n",
    "\n",
    "for i in range(len(pos_txts)):\n",
    "    with open(path +'/pos/'+pos_txts[i], 'r', errors='ignore', encoding='utf-8') as f:\n",
    "        text = f.read().strip()\n",
    "        train_texts_orig.append(text)\n",
    "        f.close()\n",
    "for i in range(len(neg_txts)):\n",
    "    with open(path +'/neg/'+neg_txts[i], 'r', errors='ignore', encoding='utf-8') as f:\n",
    "        text = f.read().strip()\n",
    "        train_texts_orig.append(text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['电影比预期要更恢弘磅礴晨昏线过后的永夜火种计划让地球流浪木星推动地球等等大小设定没想到中国也能拍这么大架构大格局的科幻片了而且是第一部了不得以前看国外科幻感觉离我们很远这一次看到熟悉的北京大裤衩上海东方明珠都变成零下89°冰天冻地的末世场景既猎奇又唏嘘虽然在剧情上有套路对于这部中国文化背景下的科幻新生儿鼓励多于挑剔导演说美国人拍科幻是放弃地球去挖掘新的人类居住地而中国人是不放弃地球守住家土的情怀希望是我们回家的唯一方向',\n",
       " '125分钟重新定义了中国科幻主创团队站在好莱坞的肩膀上完成了一个中国电影人从未完成的壮举你可以在影片中看到《星际穿越》《全球风暴》《后天》《世界末日》等一系列好莱坞顶级大片的影子但是观看的时候你依然会非常明确地认定这是一部国产科幻大片应该具有的样子没有山寨感没有违和感编剧对于大刘故事的全新演绎面面俱到小到人物情感大到人类存亡都被演绎得让人信服高潮部分更是贡献了极强的情感穿透力燃度也是惊人说实话《流浪地球》作为国产科幻元年作品起点真的太高了心疼后面那些跃跃欲试的跟风者PS：小粉红请不要赞这条我不是你们盲目爱国的盟友',\n",
       " '一定要在电影院看的电影看2D配上好音效非常燃；部分特效确实看得出瑕疵但对于中国电影来说无疑是一大进步；希望导演的下一部戏不要这么多尴尬的煽情戏尽量不要请吴京了不是因为他又红又专而是因为他真的没什么演技',\n",
       " '简直比预期好太多斯皮尔伯格凭本事证明自己还是类型片大师把歪小子斯科特的概念商业类型片化了梗用得好有埋背景里的有直接台词致敬的也有真正服务剧情的当然也免不了配角功能化反派鸡肋结局太说教这些在这部片里不太重要的毛病',\n",
       " '这才是科这才是特所以黑豹和环太平到底是什',\n",
       " '对我而言音乐梗电影梗远比游戏要更燃当然这还是一个关于游戏死宅终极梦想的故事不要以为你是重氪玩家就能统治一切胜利是最终属于我们这些零氪geek的唯一不满的是故事结局太cliche了仿佛给我这种上班中途逃出来逃避死线的观影者当头一棒',\n",
       " '彩蛋多到数不过来太喜欢这种想象四溢的电',\n",
       " '有不满的地方：反面的力量完全地根植于从现实渗入过来的威胁恫吓仿佛虚拟世界再无矛盾可我们玩游戏何时又只剩想单调的快乐呢游戏本身源源不断予以我们的失望或焦躁应该可以成为更好的反派这与结尾的逻辑相一致现实需要教育虚拟然而啊游戏玩家又如何不能反问一句：现实何以代替虚拟',\n",
       " '流行文化的狂欢个人很喜欢的爱情线还有不停歇的肾上腺素【所以说你们觉得这部好看的人快去一起玩游戏啊这就是游戏的魅力啊】01845二刷',\n",
       " '又重新看了一遍']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts_orig[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15193"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们使用tensorflow的keras接口来建模\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, Bidirectional, CuDNNLSTM\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分词和tokenize**  \n",
    "首先我们去掉每个样本的标点符号，然后用jieba分词，jieba分词返回一个生成器，没法直接进行tokenize，所以我们将分词结果转换成一个list，并将它索引化，这样每一例评价的文本变成一段索引数字，对应着预训练词向量模型中的词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\wxphx\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.082 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 进行分词和tokenize\n",
    "# train_tokens是一个长长的list，其中含有15193个小list，对应每一条评价\n",
    "train_tokens = []\n",
    "for text in train_texts_orig:\n",
    "    # 去掉标点\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # 结巴分词\n",
    "    cut = jieba.cut(text)\n",
    "    # 结巴分词的输出结果为一个生成器\n",
    "    # 把生成器转换为list\n",
    "    cut_list = [ i for i in cut ]\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            # 将词转换为索引index\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "        except KeyError:\n",
    "            # 如果词不在字典中，则输出0\n",
    "            cut_list[i] = 0\n",
    "    train_tokens.append(cut_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**索引长度标准化**  \n",
    "因为每段评语的长度是不一样的，我们如果单纯取最长的一个评语，并把其他评填充成同样的长度，这样十分浪费计算资源，所以我们取一个折衷的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得所有tokens的长度\n",
    "num_tokens = [ len(tokens) for tokens in train_tokens ]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.483643783321266"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平均tokens的长度\n",
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(np.log(num_tokens), bins = 100)  # 服从正态分布\n",
    "plt.hist(num_tokens, bins = 100)\n",
    "plt.xlim((0,500))\n",
    "plt.ylabel('number of tokens')\n",
    "plt.xlabel('length of tokens')\n",
    "plt.title('Distribution of tokens length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取tokens平均值并加上两个tokens的标准差，\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**准备Embedding Matrix**  \n",
    "现在我们来为模型准备embedding matrix（词向量矩阵），根据keras的要求，我们需要准备一个维度为$(numwords, embeddingdim)$的矩阵，num words代表我们使用的词汇的数量，emdedding dimension在我们现在使用的预训练词向量模型中是300，每一个词汇都用一个长度为300的向量表示。  \n",
    "注意我们只选择使用前50k个使用频率最高的词，在这个预训练词向量模型中，一共有260万词汇量，如果全部使用在分类问题上会很浪费计算资源，因为我们的训练样本很小，一共只有4k，如果我们有100k，200k甚至更多的训练样本时，在分类问题上可以考虑减少使用的词汇量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只使用前20000个词\n",
    "num_words = 50000\n",
    "# 初始化embedding_matrix，之后在keras上进行应用\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "# embedding_matrix为一个 [num_words，embedding_dim] 的矩阵\n",
    "# 维度为 50000 * 300\n",
    "for i in range(num_words):\n",
    "    embedding_matrix[i,:] = cn_model[cn_model.index2word[i]]\n",
    "embedding_matrix = embedding_matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 300)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_matrix的维度，\n",
    "# 这个维度为keras的要求，后续会在模型中用到\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**padding（填充）和truncating（修剪）**  \n",
    "我们把文本转换为tokens（索引）之后，每一串索引的长度并不相等，所以为了方便模型的训练我们需要把索引的长度标准化，上面我们选择了236这个可以涵盖95%训练样本的长度，接下来我们进行padding和truncating，我们一般采用'pre'的方法，这会在文本索引的前面填充0，因为根据一些研究资料中的实践，如果在文本索引后面填充0的话，会对模型造成一些不良影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行padding和truncating， 输入的train_tokens是一个list\n",
    "# 返回的train_pad是一个numpy array\n",
    "train_pad = pad_sequences(train_tokens, maxlen=max_tokens,\n",
    "                            padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超出五万个词向量的词用0代替\n",
    "train_pad[ train_pad>=num_words ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,    55,     6,     0,\n",
       "           0,    40,     0,     1,   196,   168, 12947,    38,    15,\n",
       "          62,    12,   699,    45,   112,     0,   543,     0,     4,\n",
       "         950,   197,   572,  1802,  6265,    15,  4505,     1,  4478,\n",
       "          38,  1074,    15,  1169,     1,    87,    14,  4204,   480,\n",
       "          32,  1355,     6,     7,    12,  4505,   277,     3,    34,\n",
       "        2357,    38,   303,    34,  1896,   643,   543,   643,    93,\n",
       "           1,   823])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可见padding之后前面的tokens全变成0，文本在最后面\n",
    "train_pad[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备target向量，前2000样本为1，后2000为0\n",
    "train_target = np.concatenate( (np.ones(7344),np.zeros(7849)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行训练和测试样本的分割\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90%的样本用来训练，剩余10%用来测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_pad,\n",
    "                                                    train_target,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用LSTM对样本进行分类\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型第一层为embedding\n",
    "model.add(Embedding(num_words,\n",
    "                    embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_tokens,\n",
    "                    trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(CuDNNLSTM(units=32, return_sequences=True)))\n",
    "model.add(CuDNNLSTM(units=16, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# 我们使用adam以0.001的learning rate进行优化\n",
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 92, 300)           15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 92, 64)            85504     \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 16)                5248      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,090,769\n",
      "Trainable params: 90,769\n",
      "Non-trainable params: 15,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12305 samples, validate on 1368 samples\n",
      "Epoch 1/20\n",
      "12305/12305 [==============================] - 7s 571us/step - loss: 0.2824 - acc: 0.8840 - val_loss: 0.4627 - val_acc: 0.7895\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.44926\n",
      "Epoch 2/20\n",
      "12305/12305 [==============================] - 7s 554us/step - loss: 0.2813 - acc: 0.8850 - val_loss: 0.4640 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.44926\n",
      "Epoch 3/20\n",
      "12305/12305 [==============================] - 7s 553us/step - loss: 0.2803 - acc: 0.8852 - val_loss: 0.4642 - val_acc: 0.7902\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.44926\n",
      "Epoch 4/20\n",
      "12305/12305 [==============================] - 7s 552us/step - loss: 0.2793 - acc: 0.8855 - val_loss: 0.4656 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.44926\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "model.fit(X_train, y_train,\n",
    "          validation_split=0.1, \n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结论**  \n",
    "我们首先对测试样本进行预测，得到了还算满意的准确度。  \n",
    "之后我们定义一个预测函数，来预测输入的文本的极性，可见模型对于否定句和一些简单的逻辑结构都可以进行准确的判断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520/1520 [==============================] - 1s 541us/step\n",
      "Accuracy:77.63%\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print('Accuracy:{0:.2%}'.format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    print(text)\n",
    "    # 去标点\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # 分词\n",
    "    cut = jieba.cut(text)\n",
    "    cut_list = [ i for i in cut ]\n",
    "    # tokenize\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "        except KeyError:\n",
    "            cut_list[i] = 0\n",
    "    # padding\n",
    "    tokens_pad = pad_sequences([cut_list], maxlen=max_tokens,\n",
    "                           padding='pre', truncating='pre')\n",
    "    # 预测\n",
    "    result = model.predict(x=tokens_pad)\n",
    "    coef = result[0][0]\n",
    "    if coef >= 0.5:\n",
    "        print('是一例正面评价','output=%.2f'%coef)\n",
    "    else:\n",
    "        print('是一例负面评价','output=%.2f'%coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "难看死了，千万别看，不推荐\n",
      "是一例负面评价 output=0.05\n",
      "还可以啊，喜欢呀\n",
      "是一例正面评价 output=0.84\n"
     ]
    }
   ],
   "source": [
    "test_list = [\n",
    "   '难看死了，千万别看，不推荐',\n",
    "    '还可以啊，喜欢呀'\n",
    "]\n",
    "for text in test_list:\n",
    "    predict_sentiment(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
